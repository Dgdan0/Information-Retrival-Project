{"cells":[{"cell_type":"markdown","id":"a00e032c","metadata":{"id":"hWgiQS0zkWJ5"},"source":["***Important*** DO NOT CLEAR THE OUTPUT OF THIS NOTEBOOK AFTER EXECUTION!!!"]},{"cell_type":"code","execution_count":28,"id":"5ac36d3a","metadata":{"id":"c0ccf76b","nbgrader":{"grade":false,"grade_id":"cell-Worker_Count","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"cf88b954-f39a-412a-d87e-660833e735b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["NAME         PLATFORM  PRIMARY_WORKER_COUNT  SECONDARY_WORKER_COUNT  STATUS   ZONE           SCHEDULED_DELETE\r\n","wikicluster  GCE       4                                             RUNNING  us-central1-a\r\n"]}],"source":["# if the following command generates an error, you probably didn't enable \n","# the cluster security option \"Allow API access to all Google Cloud services\"\n","# under Manage Security â†’ Project Access when setting up the cluster\n","!gcloud dataproc clusters list --region us-central1"]},{"cell_type":"markdown","id":"51cf86c5","metadata":{"id":"01ec9fd3"},"source":["# Imports & Setup"]},{"cell_type":"code","execution_count":29,"id":"bf199e6a","metadata":{"id":"32b3ec57","nbgrader":{"grade":false,"grade_id":"cell-Setup","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"fc0e315d-21e9-411d-d69c-5b97e4e5d629"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0m\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0m"]}],"source":["!pip install -q google-cloud-storage==1.43.0\n","!pip install -q graphframes"]},{"cell_type":"code","execution_count":30,"id":"d8f56ecd","metadata":{"id":"5609143b","nbgrader":{"grade":false,"grade_id":"cell-Imports","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"a24aa24b-aa75-4823-83ca-1d7deef0f0de"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["import pyspark\n","import sys\n","from collections import Counter, OrderedDict, defaultdict\n","import itertools\n","from itertools import islice, count, groupby\n","import pandas as pd\n","import os\n","import re\n","from operator import itemgetter\n","import nltk\n","from nltk.stem.porter import *\n","from nltk.corpus import stopwords\n","from time import time\n","from pathlib import Path\n","import pickle\n","import pandas as pd\n","from google.cloud import storage\n","from nltk.stem.snowball import SnowballStemmer\n","import math\n","\n","import hashlib\n","def _hash(s):\n","    return hashlib.blake2b(bytes(s, encoding='utf8'), digest_size=5).hexdigest()\n","\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":31,"id":"38a897f2","metadata":{"id":"b10cc999","nbgrader":{"grade":false,"grade_id":"cell-jar","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"8f93a7ec-71e0-49c1-fc81-9af385849a90"},"outputs":[{"name":"stdout","output_type":"stream","text":["-rw-r--r-- 1 root root 247882 Mar  8 21:37 /usr/lib/spark/jars/graphframes-0.8.2-spark3.1-s_2.12.jar\r\n"]}],"source":["# if nothing prints here you forgot to include the initialization script when starting the cluster\n","!ls -l /usr/lib/spark/jars/graph*"]},{"cell_type":"code","execution_count":32,"id":"47900073","metadata":{"id":"d3f86f11","nbgrader":{"grade":false,"grade_id":"cell-pyspark-import","locked":true,"schema_version":3,"solution":false,"task":false}},"outputs":[],"source":["from pyspark.sql import *\n","from pyspark.sql.functions import *\n","from pyspark import SparkContext, SparkConf, SparkFiles\n","from pyspark.sql import SQLContext\n","from graphframes import *"]},{"cell_type":"code","execution_count":33,"id":"72bed56b","metadata":{"id":"5be6dc2a","nbgrader":{"grade":false,"grade_id":"cell-spark-version","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"07b4e22b-a252-42fb-fe46-d9050e4e7ca8","scrolled":true},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - hive</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://wikicluster-m.c.stalwart-method-414418.internal:34619\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>yarn</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySparkShell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f50c8671780>"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["spark"]},{"cell_type":"code","execution_count":34,"id":"980e62a5","metadata":{"id":"7adc1bf5","nbgrader":{"grade":false,"grade_id":"cell-bucket_name","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["# Put your bucket name below and make sure you can access it without an error\n","bucket_name = 'wikibucket208' \n","full_path = f\"gs://{bucket_name}/\"\n","paths=[]\n","\n","client = storage.Client()\n","blobs = client.list_blobs(bucket_name)\n","for b in blobs:\n","    if b.name != 'graphframes.sh':\n","        paths.append(full_path+b.name)\n"]},{"cell_type":"code","execution_count":35,"id":"71ad8e70","metadata":{},"outputs":[],"source":["# Get some files from the bucket\n","def get_wiki_file_paths(all_wiki_files, num_files=3, all=False):\n","    # Dictionary to hold the file parts\n","    wiki_files_dict = {}\n","\n","    # Regular expression to extract file number and part\n","    file_pattern = re.compile(r\"multistream(\\d+)_?(part\\d+)?_preprocessed\\.parquet\")\n","    \n","    # Populate the dictionary with file numbers and their parts\n","    for file_path in all_wiki_files:\n","        match = file_pattern.search(file_path)\n","        if match:\n","            file_number = int(match.group(1))\n","            file_part = match.group(2) or \"part1\"  # Default to part1 if no part specified\n","\n","            if file_number not in wiki_files_dict:\n","                wiki_files_dict[file_number] = []\n","            wiki_files_dict[file_number].append((file_part, file_path))\n","\n","    # Sort the parts for each file number\n","    for file_number in wiki_files_dict:\n","        wiki_files_dict[file_number].sort()\n","    \n","    if(all):\n","        max_num = __builtin__.max(wiki_files_dict.keys())\n","        selected_files = list(sorted(wiki_files_dict.keys()))[:max_num]\n","    else:\n","        selected_files = list(sorted(wiki_files_dict.keys()))[:num_files]\n","\n","    # Collect paths, ensuring all parts of a file number are included\n","    wiki_files_paths = []\n","    for file_number in selected_files:\n","        for _, file_path in wiki_files_dict[file_number]:\n","            wiki_files_paths.append(file_path)\n","\n","    return wiki_files_paths\n"]},{"cell_type":"code","execution_count":36,"id":"d97cdb37","metadata":{},"outputs":[],"source":["NUM_BUCKETS = 150\n","bucket_name = 'wikibucket208'\n","base_dir = f'{bucket_name}'\n","\n","wiki_files_dir = f'{base_dir}/WikiFiles'\n","\n","index_filename = f'{bucket_name}/InvertedIndex/'\n","inverted_dir = f'{base_dir}/InvertedIndex'\n","posting_locs_dir = f'{inverted_dir}/posting_locs'\n","pl_body_dir = f'{posting_locs_dir}/body'\n","pl_title_dir = f'{posting_locs_dir}/title'"]},{"cell_type":"code","execution_count":37,"id":"5333d2af","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["all_files = True\n","num_wiki_files = 1   \n","\n","wiki_files_paths = get_wiki_file_paths(paths,num_wiki_files, all_files)\n","parquetFile = spark.read.parquet(*wiki_files_paths)"]},{"cell_type":"code","execution_count":38,"id":"14174dd1","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["6348910"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["# Count number of wiki pages\n","parquetFile.count()"]},{"cell_type":"markdown","id":"cac891c2","metadata":{"id":"13ZX4ervQkku"},"source":["***GCP setup is complete!*** If you got here without any errors you've earned 10 out of the 35 points of this part."]},{"cell_type":"markdown","id":"582c3f5e","metadata":{"id":"c0b0f215"},"source":["# Part 1 - Building an inverted index"]},{"cell_type":"markdown","id":"701811af","metadata":{"id":"gaaIoFViXyTg"},"source":["Let's import the inverted index module. Note that you need to use the staff-provided version called `inverted_index_gcp.py`, which contains helper functions to writing and reading the posting files similar to the Colab version, but with writing done to a Google Cloud Storage bucket."]},{"cell_type":"code","execution_count":39,"id":"121fe102","metadata":{"id":"04371c88","outputId":"327fe81b-80f4-4b3a-8894-e74720d92e35"},"outputs":[{"name":"stdout","output_type":"stream","text":["inverted_index_gcp.py\r\n"]}],"source":["# if nothing prints here you forgot to upload the file inverted_index_gcp.py to the home dir\n","%cd -q /home/dataproc\n","!ls inverted_index_gcp.py"]},{"cell_type":"code","execution_count":40,"id":"57c101a8","metadata":{"id":"2d3285d8","scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["24/03/11 12:36:20 WARN SparkContext: The path /home/dataproc/inverted_index_gcp.py has been added already. Overwriting of added paths is not supported in the current version.\n"]}],"source":["# adding our python module to the cluster\n","sc.addFile(\"/home/dataproc/inverted_index_gcp.py\")\n","sys.path.insert(0,SparkFiles.getRootDirectory())"]},{"cell_type":"code","execution_count":41,"id":"c259c402","metadata":{"id":"2477a5b9"},"outputs":[],"source":["from inverted_index_gcp import InvertedIndex"]},{"cell_type":"markdown","id":"9de4dfc9","metadata":{},"source":["Indexing Functions"]},{"cell_type":"code","execution_count":42,"id":"f3ad8fea","metadata":{"id":"a4b6ee29","nbgrader":{"grade":false,"grade_id":"cell-token2bucket","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["english_stopwords = frozenset(stopwords.words('english'))\n","corpus_stopwords = [\"category\", \"references\", \"also\", \"external\", \"links\", \n","                    \"may\", \"first\", \"see\", \"history\", \"people\", \"one\", \"two\", \n","                    \"part\", \"thumb\", \"including\", \"second\", \"following\", \n","                    \"many\", \"however\", \"would\", \"became\"]\n","\n","all_stopwords = english_stopwords.union(corpus_stopwords)\n","RE_WORD = re.compile(r\"\"\"[\\#\\@\\w](['\\-]?\\w){2,24}\"\"\", re.UNICODE)\n","\n","def token2bucket_id(token):\n","  return int(_hash(token),16) % NUM_BUCKETS\n","\n","# PLACE YOUR CODE HERE\n","# Word Count\n","# def word_count(text, id, stem_model='porter'):\n","#     tokens = [token.group() for token in RE_WORD.finditer(text.lower())]\n","#     stemmed_tokens = stem_tokens(tokens, stem_model)\n","#     filtered_tokens = [token for token in stemmed_tokens if token not in all_stopwords]\n","    \n","#     tok_dic = Counter(filtered_tokens)\n","#     doc_length = len(filtered_tokens)  # Document length after stemming and removing stopwords\n","#     result = [(token, (id, count)) for token, count in tok_dic.items()]\n","#     return (id, (result, doc_length))\n","    \n","\n","def word_count(text, id):\n","\n","  tokens = [token.group() for token in RE_WORD.finditer(text.lower())]\n","\n","  # YOUR CODE HERE\n","  stemmed_tokens = stem_tokens(tokens)\n","\n","  tok_dic = {}\n","  non_stop_tokens = [token for token in tokens if token not in all_stopwords]\n","  for token in non_stop_tokens:\n","    tok_dic[token] = tok_dic.get(token, 0) + 1\n","  result = [(token, (id, tf)) for token, tf in tok_dic.items()]\n","  return result\n","    \n","    \n","# Reduce Word Count\n","def reduce_word_counts(unsorted_pl):\n","    return sorted(unsorted_pl, key=lambda x: x[0])\n","    \n","    \n","# Calculate DF\n","def calculate_df(postings):\n","  return postings.map(lambda x: (x[0], len(x[1])))\n","    \n","    \n","# Write Partition\n","def partition_postings_and_write(postings, save_dir):\n","  def write_bucket_to_disk(bucket_id_and_postings, save_dir):\n","        # Pass both the tuple and the bucket_name to write_a_posting_list\n","    return  InvertedIndex.write_a_posting_list(bucket_id_and_postings, save_dir, bucket_name)\n","\n","\n","  postings_with_bucket_id = postings.map(lambda x: (token2bucket_id(x[0]), (x[0], x[1])))\n","  postings_grouped_by_bucket = postings_with_bucket_id.groupByKey().mapValues(list)\n","  bucket_ids = postings_grouped_by_bucket.map(\n","        lambda bucket_postings: write_bucket_to_disk((bucket_postings[0], list(bucket_postings[1])), save_dir)\n","  )\n","  return bucket_ids"]},{"cell_type":"code","execution_count":43,"id":"010e111e","metadata":{},"outputs":[],"source":["# Tokenizer\n","RE_WORD = re.compile(r\"\"\"[\\#\\@\\w](['\\-]?\\w){,24}\"\"\", re.UNICODE)\n","def tokenize(text):\n","  return [token.group() for token in RE_WORD.finditer(text.lower())]\n","\n","# Stop Words function\n","nltk_stop_words = set(stopwords.words('english'))\n","\n","corpus_stopwords = [\"category\", \"references\", \"also\", \"external\", \"links\", \n","                    \"may\", \"first\", \"see\", \"history\", \"people\", \"one\", \"two\", \n","                    \"part\", \"thumb\", \"including\", \"second\", \"following\", \n","                    \"many\", \"however\", \"would\", \"became\"]\n","all_stopwords = nltk_stop_words.union(corpus_stopwords)\n","\n","def remove_stopwords(tokens):\n","    return [token for token in tokens if token not in all_stopwords]"]},{"cell_type":"code","execution_count":44,"id":"b27ba5cb","metadata":{},"outputs":[],"source":["# Stemmer Function\n","def stem_tokens(tokens, stem_model='porter'):\n","    if stem_model == 'porter':\n","        porter = PorterStemmer()\n","        stemmed_tokens = [porter.stem(token) for token in tokens]\n","    elif stem_model == 'snowball':\n","        snowball = SnowballStemmer(language='english')\n","        stemmed_tokens = [snowball.stem(token) for token in tokens]\n","    elif stem_model == None:\n","        return tokens\n","    else:\n","        raise ValueError(\"Unsupported stem model: {}\".format(stem_model))\n","    return stemmed_tokens\n","\n","\n","# Stemmer for Postinglists\n"]},{"cell_type":"code","execution_count":45,"id":"e3775723","metadata":{},"outputs":[],"source":["# Buckets so the data will be split efficiently\n","\n","from collections import defaultdict\n","def _hash(s):\n","  return hashlib.blake2b(bytes(s, encoding='utf8'), digest_size=5).hexdigest()\n","\n","def tokens2bucket_id(token):\n","  return int(_hash(token),16) % NUM_BUCKETS"]},{"cell_type":"markdown","id":"90322e3f","metadata":{},"source":["<h2 style=\"color: blue;\">Anchor Text Index and Reverse Index</h3>\n"]},{"cell_type":"code","execution_count":59,"id":"e1f1e05a","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["24/03/11 14:02:10 WARN YarnAllocator: Container from a bad node: container_1709933818628_0021_01_000095 on host: wikicluster-w-1.c.stalwart-method-414418.internal. Exit status: 137. Diagnostics: [2024-03-11 14:02:09.887]Container killed on request. Exit code is 137\n","[2024-03-11 14:02:09.887]Container exited with a non-zero exit code 137. \n","[2024-03-11 14:02:09.887]Killed by external signal\n",".\n","24/03/11 14:02:10 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 93 for reason Container from a bad node: container_1709933818628_0021_01_000095 on host: wikicluster-w-1.c.stalwart-method-414418.internal. Exit status: 137. Diagnostics: [2024-03-11 14:02:09.887]Container killed on request. Exit code is 137\n","[2024-03-11 14:02:09.887]Container exited with a non-zero exit code 137. \n","[2024-03-11 14:02:09.887]Killed by external signal\n",".\n","24/03/11 14:02:10 ERROR YarnScheduler: Lost executor 93 on wikicluster-w-1.c.stalwart-method-414418.internal: Container from a bad node: container_1709933818628_0021_01_000095 on host: wikicluster-w-1.c.stalwart-method-414418.internal. Exit status: 137. Diagnostics: [2024-03-11 14:02:09.887]Container killed on request. Exit code is 137\n","[2024-03-11 14:02:09.887]Container exited with a non-zero exit code 137. \n","[2024-03-11 14:02:09.887]Killed by external signal\n",".\n","24/03/11 14:02:10 WARN TaskSetManager: Lost task 82.0 in stage 52.0 (TID 1598) (wikicluster-w-1.c.stalwart-method-414418.internal executor 93): ExecutorLostFailure (executor 93 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709933818628_0021_01_000095 on host: wikicluster-w-1.c.stalwart-method-414418.internal. Exit status: 137. Diagnostics: [2024-03-11 14:02:09.887]Container killed on request. Exit code is 137\n","[2024-03-11 14:02:09.887]Container exited with a non-zero exit code 137. \n","[2024-03-11 14:02:09.887]Killed by external signal\n",".\n","24/03/11 14:03:32 WARN YarnAllocator: Container from a bad node: container_1709933818628_0021_01_000093 on host: wikicluster-w-3.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:03:31.864]Container killed on request. Exit code is 143\n","[2024-03-11 14:03:31.864]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:03:31.865]Killed by external signal\n",".\n","24/03/11 14:03:32 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 91 for reason Container from a bad node: container_1709933818628_0021_01_000093 on host: wikicluster-w-3.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:03:31.864]Container killed on request. Exit code is 143\n","[2024-03-11 14:03:31.864]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:03:31.865]Killed by external signal\n",".\n","24/03/11 14:03:32 ERROR YarnScheduler: Lost executor 91 on wikicluster-w-3.c.stalwart-method-414418.internal: Container from a bad node: container_1709933818628_0021_01_000093 on host: wikicluster-w-3.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:03:31.864]Container killed on request. Exit code is 143\n","[2024-03-11 14:03:31.864]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:03:31.865]Killed by external signal\n",".\n","24/03/11 14:03:32 WARN TaskSetManager: Lost task 6.0 in stage 54.0 (TID 1771) (wikicluster-w-3.c.stalwart-method-414418.internal executor 91): ExecutorLostFailure (executor 91 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709933818628_0021_01_000093 on host: wikicluster-w-3.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:03:31.864]Container killed on request. Exit code is 143\n","[2024-03-11 14:03:31.864]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:03:31.865]Killed by external signal\n",".\n","24/03/11 14:04:07 WARN YarnAllocator: Container from a bad node: container_1709933818628_0021_01_000083 on host: wikicluster-w-2.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:04:07.658]Container killed on request. Exit code is 143\n","[2024-03-11 14:04:07.659]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:04:07.659]Killed by external signal\n",".\n","24/03/11 14:04:07 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 81 for reason Container from a bad node: container_1709933818628_0021_01_000083 on host: wikicluster-w-2.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:04:07.658]Container killed on request. Exit code is 143\n","[2024-03-11 14:04:07.659]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:04:07.659]Killed by external signal\n",".\n","24/03/11 14:04:07 ERROR YarnScheduler: Lost executor 81 on wikicluster-w-2.c.stalwart-method-414418.internal: Container from a bad node: container_1709933818628_0021_01_000083 on host: wikicluster-w-2.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:04:07.658]Container killed on request. Exit code is 143\n","[2024-03-11 14:04:07.659]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:04:07.659]Killed by external signal\n",".\n","24/03/11 14:04:07 WARN TaskSetManager: Lost task 17.0 in stage 54.0 (TID 1782) (wikicluster-w-2.c.stalwart-method-414418.internal executor 81): ExecutorLostFailure (executor 81 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709933818628_0021_01_000083 on host: wikicluster-w-2.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:04:07.658]Container killed on request. Exit code is 143\n","[2024-03-11 14:04:07.659]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:04:07.659]Killed by external signal\n",".\n","24/03/11 14:04:09 WARN YarnAllocator: Container from a bad node: container_1709933818628_0021_01_000094 on host: wikicluster-w-1.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:04:09.290]Container killed on request. Exit code is 143\n","[2024-03-11 14:04:09.290]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:04:09.291]Killed by external signal\n",".\n","24/03/11 14:04:09 ERROR YarnScheduler: Lost executor 92 on wikicluster-w-1.c.stalwart-method-414418.internal: Container from a bad node: container_1709933818628_0021_01_000094 on host: wikicluster-w-1.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:04:09.290]Container killed on request. Exit code is 143\n","[2024-03-11 14:04:09.290]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:04:09.291]Killed by external signal\n",".\n","24/03/11 14:04:09 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 92 for reason Container from a bad node: container_1709933818628_0021_01_000094 on host: wikicluster-w-1.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:04:09.290]Container killed on request. Exit code is 143\n","[2024-03-11 14:04:09.290]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:04:09.291]Killed by external signal\n",".\n","24/03/11 14:04:09 WARN TaskSetManager: Lost task 25.0 in stage 54.0 (TID 1791) (wikicluster-w-1.c.stalwart-method-414418.internal executor 92): ExecutorLostFailure (executor 92 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709933818628_0021_01_000094 on host: wikicluster-w-1.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:04:09.290]Container killed on request. Exit code is 143\n","[2024-03-11 14:04:09.290]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:04:09.291]Killed by external signal\n",".\n","24/03/11 14:04:43 WARN YarnAllocator: Container from a bad node: container_1709933818628_0021_01_000092 on host: wikicluster-w-3.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:04:43.000]Container killed on request. Exit code is 143\n","[2024-03-11 14:04:43.000]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:04:43.001]Killed by external signal\n",".\n","24/03/11 14:04:43 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 90 for reason Container from a bad node: container_1709933818628_0021_01_000092 on host: wikicluster-w-3.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:04:43.000]Container killed on request. Exit code is 143\n","[2024-03-11 14:04:43.000]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:04:43.001]Killed by external signal\n",".\n","24/03/11 14:04:43 ERROR YarnScheduler: Lost executor 90 on wikicluster-w-3.c.stalwart-method-414418.internal: Container from a bad node: container_1709933818628_0021_01_000092 on host: wikicluster-w-3.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:04:43.000]Container killed on request. Exit code is 143\n","[2024-03-11 14:04:43.000]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:04:43.001]Killed by external signal\n",".\n","24/03/11 14:04:43 WARN TaskSetManager: Lost task 13.0 in stage 54.0 (TID 1778) (wikicluster-w-3.c.stalwart-method-414418.internal executor 90): ExecutorLostFailure (executor 90 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709933818628_0021_01_000092 on host: wikicluster-w-3.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:04:43.000]Container killed on request. Exit code is 143\n","[2024-03-11 14:04:43.000]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:04:43.001]Killed by external signal\n",".\n","24/03/11 14:05:23 WARN YarnAllocator: Container from a bad node: container_1709933818628_0021_01_000090 on host: wikicluster-w-2.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:05:23.066]Container killed on request. Exit code is 143\n","[2024-03-11 14:05:23.066]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:05:23.066]Killed by external signal\n",".\n","24/03/11 14:05:23 ERROR YarnScheduler: Lost executor 88 on wikicluster-w-2.c.stalwart-method-414418.internal: Container from a bad node: container_1709933818628_0021_01_000090 on host: wikicluster-w-2.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:05:23.066]Container killed on request. Exit code is 143\n","[2024-03-11 14:05:23.066]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:05:23.066]Killed by external signal\n",".\n","24/03/11 14:05:23 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 88 for reason Container from a bad node: container_1709933818628_0021_01_000090 on host: wikicluster-w-2.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:05:23.066]Container killed on request. Exit code is 143\n","[2024-03-11 14:05:23.066]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:05:23.066]Killed by external signal\n",".\n","24/03/11 14:05:23 WARN TaskSetManager: Lost task 33.0 in stage 54.0 (TID 1801) (wikicluster-w-2.c.stalwart-method-414418.internal executor 88): ExecutorLostFailure (executor 88 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709933818628_0021_01_000090 on host: wikicluster-w-2.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:05:23.066]Container killed on request. Exit code is 143\n","[2024-03-11 14:05:23.066]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:05:23.066]Killed by external signal\n",".\n","24/03/11 14:06:10 WARN YarnAllocator: Container from a bad node: container_1709933818628_0021_01_000096 on host: wikicluster-w-1.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:06:10.429]Container killed on request. Exit code is 143\n","[2024-03-11 14:06:10.429]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:06:10.432]Killed by external signal\n",".\n","24/03/11 14:06:10 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 94 for reason Container from a bad node: container_1709933818628_0021_01_000096 on host: wikicluster-w-1.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:06:10.429]Container killed on request. Exit code is 143\n","[2024-03-11 14:06:10.429]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:06:10.432]Killed by external signal\n",".\n","24/03/11 14:06:10 ERROR YarnScheduler: Lost executor 94 on wikicluster-w-1.c.stalwart-method-414418.internal: Container from a bad node: container_1709933818628_0021_01_000096 on host: wikicluster-w-1.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:06:10.429]Container killed on request. Exit code is 143\n","[2024-03-11 14:06:10.429]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:06:10.432]Killed by external signal\n",".\n","24/03/11 14:06:10 WARN TaskSetManager: Lost task 13.1 in stage 54.0 (TID 1802) (wikicluster-w-1.c.stalwart-method-414418.internal executor 94): ExecutorLostFailure (executor 94 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709933818628_0021_01_000096 on host: wikicluster-w-1.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:06:10.429]Container killed on request. Exit code is 143\n","[2024-03-11 14:06:10.429]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:06:10.432]Killed by external signal\n",".\n","24/03/11 14:11:11 WARN YarnAllocator: Container from a bad node: container_1709933818628_0021_01_000097 on host: wikicluster-w-3.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:11:11.687]Container killed on request. Exit code is 143\n","[2024-03-11 14:11:11.687]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:11:11.687]Killed by external signal\n",".\n","24/03/11 14:11:11 ERROR YarnScheduler: Lost executor 95 on wikicluster-w-3.c.stalwart-method-414418.internal: Container from a bad node: container_1709933818628_0021_01_000097 on host: wikicluster-w-3.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:11:11.687]Container killed on request. Exit code is 143\n","[2024-03-11 14:11:11.687]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:11:11.687]Killed by external signal\n",".\n","24/03/11 14:11:11 WARN TaskSetManager: Lost task 82.0 in stage 54.0 (TID 1853) (wikicluster-w-3.c.stalwart-method-414418.internal executor 95): ExecutorLostFailure (executor 95 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709933818628_0021_01_000097 on host: wikicluster-w-3.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:11:11.687]Container killed on request. Exit code is 143\n","[2024-03-11 14:11:11.687]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:11:11.687]Killed by external signal\n",".\n","24/03/11 14:11:11 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 95 for reason Container from a bad node: container_1709933818628_0021_01_000097 on host: wikicluster-w-3.c.stalwart-method-414418.internal. Exit status: 143. Diagnostics: [2024-03-11 14:11:11.687]Container killed on request. Exit code is 143\n","[2024-03-11 14:11:11.687]Container exited with a non-zero exit code 143. \n","[2024-03-11 14:11:11.687]Killed by external signal\n",".\n","                                                                                \r"]}],"source":["def map_anchor_text(anchor_text_rows, doc_id):\n","    bucket_id = tokens2bucket_id(str(doc_id))\n","    anchor_ids = [anchor_row.id for anchor_row in anchor_text_rows]  # Corrected variable name\n","    return (bucket_id, (doc_id, anchor_ids))\n","\n","def reduce_anchor_text(bucket_id, vals):\n","    anchor_dict = {doc_id: anchor_ids for doc_id, anchor_ids in vals}\n","    serialized_dict = pickle.dumps(anchor_dict)\n","    write_anchor_to_gcp(bucket_name, 'InvertedIndex/anchor_text/index', bucket_id, serialized_dict)\n","\n","def write_anchor_to_gcp(bucket_name, save_dir, bucket_id, serialized_dict):\n","    client = storage.Client()\n","    bucket = client.bucket(bucket_name)\n","    blob_name = f'{save_dir}/{bucket_id}_anchor_text.pickle'\n","    blob = bucket.blob(blob_name)\n","    blob.upload_from_string(serialized_dict)\n","\n","\n","doc_text_pairs = parquetFile.select(\"anchor_text\", \"id\").rdd\n","rdd_mapped = doc_text_pairs.map(lambda x: map_anchor_text(x[0], x[1]))\n","rdd_grouped = rdd_mapped.groupByKey().mapValues(list)  # slightly simplified\n","rdd_grouped.foreach(lambda x: reduce_anchor_text(x[0], x[1]))\n","\n","    \n","    \n","# Reverse anchor text index\n","\n","def map_source_to_target(anchor_text_rows, doc_id):\n","        anchor_ids = [anchor_row.id for anchor_row in anchor_text_rows]\n","        return [(anchor_id, doc_id) for anchor_id in anchor_ids]\n","\n","# Define the first reducer to group by target_doc_id\n","def reduce_to_bucket(tuple_data):\n","    target_doc_id, source_doc_ids_iter = tuple_data\n","    source_doc_ids = list(source_doc_ids_iter)  # Convert iterator to list\n","    bucket_id = tokens2bucket_id(str(target_doc_id))\n","    return (bucket_id, (target_doc_id, source_doc_ids))\n","        \n","def reduce_anchor_text(bucket_id, vals):\n","    anchor_dict = {doc_id: anchor_ids for doc_id, anchor_ids in vals}\n","    serialized_dict = pickle.dumps(anchor_dict)\n","    write_anchor_to_gcp(bucket_name, 'InvertedIndex/anchor_text/reverse_index', bucket_id, serialized_dict)\n","\n","\n","doc_text_pairs = parquetFile.select(\"anchor_text\", \"id\").rdd\n","rdd_mapped = doc_text_pairs.flatMap(lambda x: map_source_to_target(x[0], x[1]))\n","# Corrected from mapped_rdd to rdd_mapped\n","grouped_by_target_doc_id = rdd_mapped.groupByKey().map(reduce_to_bucket)\n","grouped_by_bucket_id = grouped_by_target_doc_id.groupByKey()\n","grouped_by_bucket_id.foreach(lambda x: reduce_anchor_text(x[0], x[1]))\n","    "]}],"metadata":{"celltoolbar":"Create Assignment","colab":{"collapsed_sections":[],"name":"assignment3_gcp.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":5}